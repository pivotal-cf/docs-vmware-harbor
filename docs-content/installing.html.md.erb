---
title: Installing and Configuring VMware Harbor Registry
owner: Partners
---

This topic describes how to install and configure VMware Harbor Registry using Pivotal Ops Manager
for use with <%= vars.product_pks_full %> and VMware Tanzu Application Service for VMs (TAS for VMs).

For more information about <%= vars.product_pks_short %>, see the [<%= vars.product_pks_full %>](https://docs.pivotal.io/pks/index.html) documentation.

For more information about TAS for VMs, see [TAS for VMs Concepts](https://docs.pivotal.io/pivotalcf/concepts/index.html) in the Pivotal documentation.

<p class="note"><strong>Note:</strong> This documentation supports the Harbor v1.9.x and 1.10.x releases.</p>

## <a id='prereqs'></a> Prerequisites

You must have installed <%= vars.product_pks_short %>. For more information, see [Installing <%= vars.product_pks_short %>](https://docs.pivotal.io/pks/installing.html) in the <%= vars.product_pks_short %> documentation.

These instructions are valid for new installations, reconfigurations of existing installations, or upgrades. If you are upgrading Harbor, follow the procedure in [Upgrading VMware Harbor Registry](upgrading.html) before performing these steps.

## <a id='install'></a> Import Harbor Tile to Ops Manager

1. Download the Harbor tile from [Pivotal Network](https://network.pivotal.io/).
1. Log in to the Ops Manager **Installation Dashboard**.
1. Click **Import a Product** and upload the Harbor tile.
1. Below the **Import a Product** button, click the **+** next to the VMware Harbor Registry version number to add the tile to your staging area.
1. Click the **VMware Harbor Registry** tile to begin the configuration process.

    ![Add and Configure Harbor Tile](images/add-harbor-tile-vsphere.png)
    [View a larger version of this image.](images/add-harbor-tile-vsphere.png)

## <a id='configure_az_networks'></a> Assign AZs and Networks

1. In the Harbor tile, select **Assign AZs and Networks**.
1. In the **Assign AZs and Networks** pane, under **Place singleton jobs in**, select the availability zone (AZ) where you want to run singleton jobs. VMware Harbor is a singleton job and is placed on this network.
1. Under **Balance other jobs in**, select the AZ where you want to balance other jobs. For <%= vars.product_pks_short %>, this is the same AZ as the one that you selected for **Place singleton jobs in**.
1. Under **Network**, select the network where you want to deploy Harbor. For <%= vars.product_pks_short %>, this is the management network where you deploy the Ops Manager, BOSH Director, and <%= vars.product_pks_short %> virtual machines (VMs).
1. Click **Save** to preserve your changes.
<img src="images/assign-azs-networks.png" alt="Assign AZs and Networks for Harbor" width="725">

## <a id='configure_general'></a> Configure General Settings

1. In the Harbor tile, select **General**.
<img src="images/config-general-settings-default.png" alt="Configure General Settings for Harbor" width="725">
1. Under **Hostname**, enter the FDQN of a host to access the Harbor administration UI and registry service. The hostname must include a domain and must be able to resolve to the IP address of the Harbor instance VM by an external DNS server.
<br><br>
Kubernetes worker nodes can resolve the Harbor FQDN through the local BOSH DNS server. To enable Docker clients external to Kubernetes worker nodes to resolve the Harbor FQDN, you must provide a Harbor FQDN that can be resolved by an external DNS server. When Harbor is successfully deployed, you must update the Harbor external DNS record with the IP address of the Harbor VM.
1. **Optionally** Under **Static IP Address**, enter the static IP address that you want to use for the Harbor web interface. This static IP address must be inside the netblock used for the 'Network' above. Create a DNS record that maps the Harbor FQDN to the static IP address.
<br><br>
If a static IP address is not used, the external IP assigned by BOSH or a custom load balancer will need to direct traffic to the hostname specified above.
1. Optionally modify the **Wait time for Harbor Tile migration complete** from the default of 60 minutes. This option is available in v1.9.x and later. 
1. Click **Save**.

In previous releases, this page also includes the container network settings. In 1.9.x, those settings are now in the **Networking** section. See [Configure Networking](#configure_networking) for details. The 

## <a id='configure_certificate'></a> Configure SSL Certificate and Key

On the **Certificate** pane, you configure the SSL certificate and private key for Harbor. You can generate the certificate and private key or provide a custom signed certificate and private key. Additionally, you must provide the Certificate Authority (CA) certificate, which is used to sign the Harbor certificate. The domain name used to generate RSA certificate in the Harbor Tile can be different than the domain name used to generate the RSA certificate in the <%= vars.product_pks_tile %> or TAS for VMs tile.

If this is an existing instance of Harbor that you are reconfiguring or upgrading, you can change the previous certificate by clicking **Change**. You can then either generate a new RSA certificate or add a new custom certificate, key, and CA. 

### <a id='generate_cert'></a>Use a Generated Certificate

To use a certificate that Ops Manager generates automatically, follow the steps below.

1. In the Harbor tile, select **Certificate**.
1. Click **Generate RSA Certificate**.
1. Enter the domain for your Harbor instance in the **Generate RSA Certificate** field. This can be a standard FQDN or a wildcard domain. The domain must match the DNS resolvable domain name that you used when you specified the hostname for Harbor.
1. Click **Generate**.
1. Click **Save**.
<br><br>
    <img src="images/generate-rsa-cert.png" alt="Generate RSA Certificate for Harbor" width="425">
<br><br>

    <p class="note"><strong>Note:</strong> If you use a wildcard domain name, be sure to truncate it appropriately. For example: "SSL: certificate subject name (*.harbor.pks.corp.local) does not match target host name (harbor.pks.corp.local)." In this case, the proper wildcard name for the cert is "*.pks.corp.local".</p>

### <a id='custom_cert'></a>Use a Custom Certificate

To use a custom signed certificate from a third-party CA, follow the steps below.

1. In the Harbor tile, select **Certificate**.
1. Copy the contents of your certificate file into the **Certificate PEM** field. Certificates must be in PEM-encoded format. The certificate CN or SAN must match the DNS-resolvable domain name that you used as the hostname for Harbor.
1. Copy the contents of the corresponding key (PEM) into the **Private Key PEM** field.
1. Enter the **Certificate Authority (CA)** for the server certificate, which is used to sign the Harbor certificate. If you use a self-signed certificate, copy the corresponding CA here. Leave this field empty if you are using the root CA of Ops Manager.

    If you use a certificate for Enterprise PKS that is not signed by the default Ops Manager CA, and you configure Harbor to use the Enterprise PKS UAA for authentication, enter the root certificate of the Enterprise PKS UAA, so that Harbor can trust the correct certificate.
1. Click **Save**.

    <img src="images/cert-config.png" alt="Configure SSL certificate and private key for Harbor" width="725">

## <a id='configure_credentials'></a> Configure Harbor Credentials

If you are configuring an initial installation of Harbor, these credentials are used for the first login to the Harbor interface. If you are reconfiguring or upgrading Harbor, you cannot change the initial credentials. If you have changed the credentials in the Harbor interface since the initial installation, see [Update Harbor Credentials](#update-creds) below.

### <a id='initial-creds'></a> Configure Initial Credentials

1. Select **Credentials**.
1. Enter the password for the Harbor system administrator account. The default Harbor user name is `admin`. Both the user name and password can be changed after installation using the Harbor web interface. See instructions below.
    <p class="note"><strong>Note:</strong> The password must contain at least 8 characters with 1 lowercase letter, 1 uppercase letter and 1 numeric character. The password cannot start with the pound sign `#`.</p>
1. Click **Save**.

    <img src="images/harbor-credentials.png" alt="Configure Harbor Credentials" width="725">

### <a id='update-creds'></a> Update Harbor Credentials

You cannot change the Harbor administrator password in Ops Manager after you set it during installation. You must use the Harbor interface to make subsequent changes to the password after deployment.

1. Update the Harbor system administrator password using the Harbor web interface.
1. In the **Credentials** section of the Harbor tile, enter the new password in the **Admin Password to run smoke test** field.
1. Apply changes to the Harbor tile and redeploy Harbor using Ops Manager for the updated password to take effect.

## <a id='configure_authentication'></a> Configure Harbor Authentication Mode

On the **Authentication** pane in Ops Manager you select an authentication mode. You use the Harbor web console to configure detailed settings for the selected authentication mode. For more information, see <a href="https://github.com/goharbor/harbor/blob/master/docs/user_guide.md#managing-authentication">Managing authentication</a> in the Harbor User Guide in GitHub.

If you are reconfiguring or upgrading Harbor, you cannot change the authentication mode that was set during the initial installation.

1. In the Harbor tile, select **Authentication**.
1. Choose one of the following Authentication Modes:
   - **Internal** (default): Harbor user credentials are stored in a local database
   - **LDAP**: LDAP authentication
   - **UAA in <%= vars.product_pks_short %>**: User Account and Authentication with <%= vars.product_pks_short %>
   - **UAA in VMware Tanzu Application Service for VMs**: User Account and Authentication with TAS for VMs
1. Click **Save**.

## <a id='configure_networking'></a> Configure Networking

You can optionally configure a global proxy that is used by Harbor and Clair. You can also customize the container network settings. 

The **Networking** section is new in version 1.9.x. In previous releases, you could only set a proxy for Clair, so those settings were in the **Clair** section. In previous releases, the container network settings were in the **General** section.

1. In the Harbor tile, select **Networking**.
1. (Optional) In the **HTTP Proxy** and **HTTPS Proxy** fields, enter the URL to proxy traffic for Harbor server components, such as Clair, the jobservice, and to access the external network. 
<br><br>
   For example: `http://my.proxy.com:3128`. Set both the HTTP and HTTPS proxy options. Usually HTTPS is used, because most sites use HTTPS.
<br>
    <p class="note"><strong>Note:</strong> To use basic authentication with the HTTP/S proxy, include the user name and password in the proxy host URL, for example: <code>http<span>:</span>//user:password<span>@<span>myproxy.internal.domain:8080</code>.</p>
<br>
    <p class="note"><strong>Note:</strong> Some proxy servers change the certificate of the HTTPS site and replace it with a self-signed certificate generated with the proxy server root ca. If the proxy server's root ca is not trusted by the client, the proxy server will return a "X509 certificate singed by unknown authority" error. To avoid this error, either a) add the proxy server's root certificate to the Ops Manager trusted CA list (instructions <a href="https://docs-pcf-staging.cfapps.io/partners/vmware-harbor/integrating-pks.html#provide-harbor-cert">instructions</a>), or b) contact the administrator of the proxy server and request to add the HTTPS site URL to the proxy server whitelist so that the original HTTPS certificate is not replaced. You can use the following command to check if the original server certificate is replaced by the proxy server certificate: `curl -x <proxy_server_url> -v https://auth.docker.io`. If the proxy server replaced the certificate, the proxy server fails to verify the certificate when it passes through the proxy server.</p>      
1. (Optional) In the **No Proxy** field, specify the endpoints that will bypass the proxy host. The required values, `127.0.0.1,localhost,core,registry`, are populated by default.

    <img src="images/networking1.png" alt="Configure proxies for Harbor" width="725">

1. By default Docker assigns each running container a private IP address. To use the default container network settings, select **Keep the default container network settings**.
1. To customize the container network settings, select **Specify customized container network settings**.

    <img src="images/networking2.png" alt="Configure proxies for Harbor" width="725">

    If you select **Specify customized container network settings**, you must specify at least one address pool base and size. When a Docker container starts, the Docker daemon (dockerd) selects an IP address from the address pool and allocates it to the container.

    Because the smallest network in Docker private network is `a.b.c.d/28`, if you input only one pool, the smallest CIDR block is `a.b.c.d/25`. If input two pools, the smallest CIDR block is `a.b.c.d/26`. 

    <p class="note"><strong>Note:</strong> There are 10 networks in the Harbor VM. Make sure there are enough subnetworks in the specified CIDR. If there are not enough subnets in the network, the Harbor server fails to start.</p>

    For example, if you select this option, for the **Address pool1 base** you might enter `172.31.0.0/25`, and for the **Address pool1 size** you might enter `28`. Additional entry pairs are optional.
1. Click **Save**.

## <a id='configure_storage'></a> Configure Container Registry Storage

On the **Container Registry Storage** pane you specify the type of file storage to use for storing container images.

1. In the Harbor tile, select **Container Registry Storage**.
1. Choose one of the following as your desired storage for container images.
  - **Local File System** (default)
  - [Remote NFS Server](#nfs)
  - [AWS S3](#aws)
  - [Google Cloud Storage](#gcp)
  - [Azure Storage](#azure)  

    See the sections below for configuration instructions.

1. Click **Save**.

### <a id='nfs'></a> Remote NFS Server Configuration

If you choose **Remote NFS Server**, provide the **NFS Server Address** in the form `nfs_server_ip:/path/to/export_directory`.
For example: `192.0.2.0:/harbor/registry/export`.

The user/group ID (UID) for the owner of the export directory on the NFS Server must be 10000:10000, where 10000 is the UID used by the Harbor Registry container.

<img src="images/nfs.png" alt="NFS Server configuration for Harbor" width="725">

### <a id='aws'></a> AWS S3 Configuration

<p class="note"><strong>Note:</strong> The Harbor Registry tile officially supports AWS S3 storage only. Other S3-compatible object stores, such as Amazon ECS and Minio, are not officially supported.</p>

If you choose **AWS S3**, configure the following settings:

- **Access Key**: The access key for your S3 bucket.
- **Secret Key**: The secret key for your S3 bucket.
- **Region**: The AWS region where your S3 bucket is located.
- **Endpoint URL of your S3-compatible file store**: The URL of your S3-compatible filestore. If you are using the AWS S3 service, leave this field empty.
- **Bucket Name**: The name you gave your S3 bucket when you created it.
- **Root Directory in the Bucket**: The root directory of your S3 bucket. This field is optional.
- **Chunk Size**: The default value is `5242880` (5&nbsp;MB).
- **Enable v4auth**: Access to your S3 bucket is authenticated by default. Deselect this checkbox for anonymous access.
- **Secure Mode**: Access to your S3 bucket is secure by default. Deselect this checkbox to disable secure mode.

    <img src="images/aws.png" alt="AWS S3 configuration for Harbor" width="725">

<p class="note"><strong>Note:</strong> When using Harbor with an S3-compatible object store, the object store must be configured with a TLS cipher suite supported by the Docker client. If the S3 bucket is not configured with a compatible cipher suite, when performing a <code>docker push</code> command to the Harbor Registry, you receive the following: "remote error: tls: handshake failure". The Harbor Registry redirects the connection from the Docker client to the S3-compatible object store. The TLS handshake is between the Docker client and the S3-compatible object store. To address this error, you must determine the cipher suites supported by the Docker client and S3-compatible object store, and ensure that there is at least one common cipher suite between them.</p>

### <a id='gcp'></a> Google Cloud Storage Configuration

If you selected **Google Cloud Storage**, configure the following settings:

- **Bucket Name**: The name you gave your bucket when you created it.
- **Root Directory in the Bucket**: The root directory of your bucket. This field is optional.
- **Chunk Size**: The default value is `5242880` (5&nbsp;MB).
- **Key File**: The service account key for your bucket.

    <img src="images/google.png" alt="Google Cloud Storage configuration for Harbor" width="725">

### <a id='azure'></a> Azure Storage Configuration

If you selected **Azure Storage**, configure the following properties (all are required):

- **Account Name**: Name of the Azure Storage Account.
- **Account Key**: Primary or Secondary Key for the Storage Account.
- **Container**: Name of the Azure root storage container in which all registry data is stored. The name must comply with the [Azure container name requirements](https://docs.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata).
- **Realm**: Domain name suffix for the Storage Service API endpoint. The default is `core.windows.net`. Examples: The realm for "Azure in China" is `core.chinacloudapi.cn`. The realm for "Azure Government" is `core.usgovcloudapi.net`.

    <img src="images/azure-storage.png" alt="Azure Storage configuration for Harbor" width="725">

## <a id='configure_clair'></a> Configure Container Vulnerability Scanning Using Clair

Clair is an open-source project for the static analysis of vulnerabilities in Docker and appc containers. For more information about Clair, see the [Clair](https://github.com/coreos/clair) repository in GitHub.

Harbor provides the ability to install and use Clair for vulnerability scanning of container images. Clair can be configured to update its Common Vulnerabilities and Exposures (CVE) databases from the Internet by setting the **Updater Interval**. In an intranet network environment, configure a proxy to access the Internet.

<p class="note"><strong>Note:</strong> You must change the default <b>Updater interval (Hours)</b> field to ensure that the Clair CVE databases are kept current. See instructions below.</p>

1. In the Harbor tile, select **Clair Settings**. 
1. To enable container image vulnerability scanning, ensure **Install Clair** is selected.
If you deselect this checkbox, Clair is not installed

1. In the **Updater interval (Hours)** field, specify when Clair will update its CVE databases for the registered sources. When the updater interval expires, Clair will update its CVE databases. The default updater interval is `0`, which means Clair will never update its CVE databases. If you set the updater interval to `24`, Clair updates its CVE databases every 24 hours. 
<br><br>
For a list of the CVE databases that Clair uses, see [Data Sources for the built-in drivers](https://github.com/coreos/clair/blob/master/Documentation/drivers-and-data-sources.md#data-sources-for-the-built-in-drivers) in the Clair documentation.

1. Click **Save**.

    <img src="images/clair2.png" alt="Clair configuration for Harbor" width="725">
    
In previous releases, the **Clair** section included proxy settings, because you could only set a proxy for Clair. In version 1.9.x, you can set a global proxy for use by Harbor and Clair. In 1.9.x, the proxy settings for Clair are in the **Networking** section. See [Configure Networking](#configure_networking) for information about how to set proxies for Clair.

## <a id='configure_notary'></a> Configure Container Signing Using Docker Notary

Harbor provides Docker Notary for container signing and trust. Notary is installed by default. For more information about Docker Notary, see [Getting started with Docker Notary](https://docs.docker.com/notary/getting_started/) in the Docker documentation.

1. In the Harbor tile, select **Notary Settings**.
1. By default, **Install Notary** is selected. Deselect to not install Notary.
1. Click **Save**.

## <a id='configure_vm-monitor'></a> (Optional) Configure VM Monitor Settings

[Wavefront](https://www.wavefront.com/) is a high-performance streaming analytics platform that helps you monitor and optimize your environment. To use Wavefront monitoring with Harbor, you enable it in the Harbor tile and configure a few parameters. 

Wavefront must be installed, licensed, running, and available in your environment before you enable the option. 

1. Go to [www.wavefront.com](https://www.wavefront.com/sign-up/) and sign up. You will receive an API server and a token.
1. In the Harbor tile, select **VM Monitor Settings**. 
1. For the **Choose monitor for VM** option, select **Enable VM monitor with Wavefront**.
1. Configure the following three parameters:
	1. **Wavefront URL**: Enter the Wavefront API server URL where the performance metrics are sent to.
	1. **Wavefront Token**: Enter the token to access the Wavefront API server.
	1. **Hostname** (optional): All metrics sen to the Wavefront API server are categorized to a hostname. Keep this field blank if you want to use the same hostname that was used for the Harbor FQDN.
1. Click **Save**.
    <img src="images/harbor-monitoring.png" alt="Harbor Monitoring using Wavefront" width="725">

<p class="note"><strong>Note:</strong> To monitor the Harbor VM with Wavefront, you will need to deploy the Wavefront dashboard. See <a href="./integrating-pks.html#wavefront">Monitor Harbor with Wavefront</a> for details.</p>

## <a id='configure_logger'></a> Configure Harbor Logger

You can configure Harbor so that an existing deployment of VMware vRealize Log Insight pulls logs from the Harbor instance.

After enabling Harbor integration with vRealize Log Insight, all Harbor application logs are sent to the vRealize Log Insight server. The local Harbor VM no longer contains the Harbor application logs. You must access them through vRealize Log Insight.

vRealize Log Insight must be installed, licensed, running, and available in your environment before you enable the option. For instructions and additional information, see the [vRealize Log Insight documentation] (https://docs.vmware.com/en/vRealize-Log-Insight/index.html).

To configure vRealize Log Insight integration with Harbor, the vRealize Log Insight server must be accessible on the local network. Access to the vRealize Log Insight server through an HTTP/S proxy server is not supported.

1. Go to www.wavefront.com and sign up. You will receive an API server and a token.
1. In the Harbor tile, select **Logging**. 
1. For the **Enable VMware vRealize Log Insight Integration** option, select **true** to enable vRealize Log Insight integration.
1. For the **Protocol**, select **TCP** or **UDP**.
1. For **Address**, enter the address of your vRealize Log Insight instance.
1. For **Port**, enter the port on which your vRealize Log Insight instance listens.
1. Click **Save**.

    <img src="images/harbor-vrli.png" alt="Harbor Logging using vRealize Log Insight integration" width="725">
    
## <a id='configure_errands'></a> Configure BOSH Deployment Errands

Deployment errands are BOSH scripts that run at designated points during an installation using Ops Manager.

1. In the Harbor tile, select **Errands**.
1. For **Post-deploy Errands**, select the **smoke-testing** errand:
   - **On** (default)
   - **Off**
1. For **Pre-delete Errands**, select the **deregister Harbor UAA client** errand:
   - **On**
   - **Off** (default)
1. Click **Save**.

## <a id='configure_resource_config'></a> Configure Harbor VM Resources

The Harbor VM runs as a single instance. On the **Resource Config** pane in Ops Manager you configure the resource settings for the Harbor VM, including disk size and type. If you are deploying Harbor on AWS or GCP, you can specify a load balancer that allows external access to the Harbor VM.

For standard Harbor Registry deployments, the default size and type for the Harbor VM are sufficient. The compute and storage capacity of the Harbor VM depends on the size of the images you are deploying to the Harbor registry. Some images are 30&nbsp;MB, while others are 2&nbsp;GB. In addition, storage requirements depend on how images are built and what base images are leveraged. In general, if your Harbor instance manages a large number of images, increase the storage size and select a VM type that has greater CPU capacity and more RAM. Using a smaller size VM than the default is not common.

If you are deploying Harbor using BOSH Director for AWS or GCP, and you are fronting the Harbor VM with a load balancer, provide its IP address in the resource settings. AWS and GCP load balancers can be internal or external. The load balancer type dictates whether you need to select or deselect the **Internet Connected** checkbox. The image below shows the load balancer "scheme" options for the AWS classic load balancer. For more information, see the following topics:

* <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-internal-load-balancers.html?icmpid=docs_elb_console">Internal Classic Load Balancers</a> in the AWS documentation.
* <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-internet-facing-load-balancers.html">Internet-Facing Classic Load Balancers</a> in the AWS documentation.
* <a href="https://cloud.google.com/load-balancing/docs/load-balancing-overview#external_versus_internal_load_balancing">External versus internal load balancing</a> in _Overview of Load Balancing_ in the GCP documentation.

    <img src="images/aws-elb.png" alt="AWS ELB Type" width="725">

To configure the Harbor VM resources, follow the instructions below.

1. In the Harbor tile, click **Resource Config**.
1. To change the configuration of the `harbor-app` VM, edit the following properties:
  - **Instances**: This value cannot be changed. PCF supports one Harbor instance only.
  - **Persistent Disk Type**: Increase or decrease the storage capacity of the Harbor disk.
  - **VM Type**: Select a VM type with more CPU capacity and RAM depending on your storage requirements.
1. To change the configuration of the `smoke-testing` VM, specify the desired **VM Type**. This is an ephemeral VM deployed and used by BOSH to test the deployment of the Harbor VM. Typically, the default size is sufficient. However, if you change the size of the `harbor-app` VM from the default, you may need to adjust the size of the `smoke-testing` VM accordingly.
1. For AWS and GCP environments, specify the name of the load balancer that allows external access to the Harbor VM. If you are using an Internet-facing load balancer, select the **Internet Connected** checkbox. If the load balancer is internal, deselect the checkbox.
1. Click **Save**.

    <img src="images/aws-elb-config.png" alt="Harbor Configuration with ELB" width="725">

## <a id='configure_stemcell'></a> Update the Stemcell Version

If the version of the Harbor tile that you are installing requires a more recent stemcell version than is currently deployed in Ops Manager, the Harbor tile displays a "Missing stemcell" error message.

<img src="images/missing-stemcell.png" alt="Missing stemcell for Harbor" width="225">

To update the stemcell, follow the steps below.

1. In Ops Manager, return to the **Installation Dashboard**.
1. Click the Harbor tile.
1. In the Harbor tile, click the **Missing stemcell** link.
1. In the **Stemcell Library**. record the name and version of the required stemcell for Harbor.
<img src="images/required-stemcell.png" alt="Required stemcell for Harbor" width="625">
1. Log in to [Pivotal Network](https://network.pivotal.io/).
1. Search for **Stemcells for PCF (Ubuntu Xenial)**.
1. Download the required Harbor stemcell for your platform to the Ops Manager host. For example, if you are using vSphere, download the BOSH stemcell for vSphere that matches the version that you recorded in a previous step.
1. In Ops Manager, return to the **Installation Dashboard**.
1. On the Harbor tile, click the **Missing stemcell** link.
1. Click **Import Stemcell**, navigate to the stemcell you downloaded, and click **Open** to import the stemcell.
<img src="images/import-stemcell.png" alt="Import required stemcell for Harbor" width="625">
1. When prompted, apply the imported stemcell to the Harbor product.

## <a id='deploy'></a> Deploy Harbor Registry

1. Return to the Ops Manager **Installation Dashboard**.
1. Click **Review Pending Changes** > **Apply Changes** to deploy Harbor.
<img src="images/deploy-harbor.png" alt="Deploy Harbor" width="625">

## <a id='post-deploy'></a> View Harbor VM Information

When the deployment finishes, verify the deployment by checking the Harbor instance information the **Harbor** tile in Ops Manager.

1. Select the **Status** tab to see the IP address of the Harbor host and status information about the Harbor VM.
2. Select the **Credentials** tab to see Harbor credentials, including the Harbor administrator account for SSH access to the VM and the Clair database credentials.
3.  Select the **Logs** tab to collect Harbor log files and generate and download the Harbor log bundle.

	 <img src="images/harbor-ip.png" alt="Get Harbor IP" width="625">

## <a id='use'></a> Next Steps

After you install and configure Harbor, you must update the DNS entry for Harbor and provide the Harbor CA certificate to Ops Manager. If you use <%= vars.product_pks_short %> with NSX-T, define a NAT rule to the Harbor IP address.

- Update the DNS entry for the Harbor hostname with the IP address of the Harbor VM assigned by BOSH. See [Update DNS for Harbor](./integrating-pks.html#update-dns) in _Integrating VMware Harbor Registry with <%= vars.product_pks_short %>_.
- Obtain the Harbor CA certificate and provide it to Ops Manager:
  - [<%= vars.product_pks_short %> instructions](./integrating-pks.html#provide-harbor-cert)
  - [TAS for VMs instructions](https://docs.pivotal.io/pivotalcf/opsguide/docker-registry.html#ops-man)
- If you are using Harbor with <%= vars.product_pks_short %> with NSX-T in NAT mode, you must create a DNAT rule to access the Harbor UI. See [Create DNAT Rule (NSX-T)](./integrating-pks.html#create-dnat-harbor) in _Integrating VMware Harbor Registry with <%= vars.product_pks_short %>_.
- Start Harbor and log in. See [Starting Harbor](./using.html#starting) in _Using VMware Harbor Registry_.
- Use Harbor. See [Using Harbor](./using.html#using) in _Using VMware Harbor Registry_.
